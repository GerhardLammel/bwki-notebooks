{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 15\n",
    "\n",
    "_Wie du merkst, ist es trotzdem noch sehr schwer, die Parameter durch Ausprobieren zu finden. Jetzt stell dir mal vor, man müsste das für alle Merkmale der Hunde machen._\n",
    "\n",
    "_Wir müssen also ein Verfahren entwickeln, das die besten Parameter für uns findet. Häufig verwendet man dafür das Gradientenverfahren – auf [YouTube](https://www.youtube.com/watch?v=trA2pbxzTjE) und \n",
    "[Wikipedia](https://de.wikipedia.org/wiki/Gradientenverfahren) kannst du dich dazu informieren, bevor wir weitermachen._\n",
    "\n",
    "_Um das Gradientenverfahren anwenden zu können, müssen wir den Gradienten, also die Richtung mit den größten Abstieg, der Kostenfunktion kennen. Den erhalten wir, indem wir die Kostenfunktion ableiten:_\n",
    "\n",
    "$$\\frac{dh(features, w_j, b)}{dw_j} = (h(features, w_j, b) - y) x_i$$\n",
    "\n",
    "$$\\frac{dh(features, w_j, b)}{db} = (h(features, w_j, b) - y)$$\n",
    "\n",
    "_`y` ist hier wieder das Label (gesund / krank) des jeweiligen Hundes. Wir wollen das Gradientenverfahren anwenden, um Gewichte und den Bias zu finden, die uns die beste Diagnose liefern. Dazu musst du eine Funktion schreiben, die bei jedem Schritt die Werte anpasst. Die Werte werden immer in Richtung des Gradienten verändert. Das heißt, du musst in der Funktion derivative_cost die Ableitungen der Kostenfunktion anwenden._\n",
    "\n",
    "_Nur für dein Interesse: In unserem Test, der dir ausgibt, ob dein Ergebnis richtig ist, starten wir den ersten Schritt, indem wir alle Gewichte und den Bias auf 1 setzen und die Lernrate auf `alpha = 0.0001`. Wenn du in deinem Jupyter notebook deine Funktionen testest, kannst du auch diese Werte übernehmen._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Daten laden\n",
    "D = np.load('data/train_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    s = ...\n",
    "    return s\n",
    "\n",
    "def h(X, w1, w2, b):\n",
    "    v = ...\n",
    "    return v\n",
    "\n",
    "def derivative_cost(X, Y, w1, w2, b):\n",
    "    m = X.shape[0]\n",
    "    d_w1 = ...\n",
    "    d_w2 = ...\n",
    "    d_b = ...\n",
    "    return d_w1, d_w2, d_b\n",
    "\n",
    "def step(D, w1, w2, b, alpha):\n",
    "    ...\n",
    "    w1_new = ...\n",
    "    w2_new = ...\n",
    "    b_new = ...\n",
    "    return w1_new, w2_new, b_new"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
